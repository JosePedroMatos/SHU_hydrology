{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592290ed-e0aa-459a-83d3-25ae06a37e96",
   "metadata": {},
   "source": [
    "# Working with precipitation files in Python\n",
    "\n",
    "You will need to:\n",
    "- Import modules that are important to complete the work.\n",
    "- Load the files and \"understand\" them.\n",
    "- Join the files in a large matrix.\n",
    "- Compute statistics.\n",
    "- Save the files for later use.\n",
    "\n",
    "Optionally:\n",
    "- Create plots\n",
    "\n",
    "### Do not forget to run all cells in order, from top to bottom. Failing to do so may cause errors.\n",
    "### AI Large Language Models (such as deepseek) can help you a lot doing this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b8199-99f6-4d01-8f98-09c5e2fb5ded",
   "metadata": {},
   "source": [
    "## Modules\n",
    "\n",
    "Some useful modules are:\n",
    "- `pandas` (https://pandas.pydata.org/docs/getting_started/intro_tutorials/): to work with tabular data (including import and export). It is the \"Microsoft Excel\" of Python.\n",
    "- `matplotlib` (https://matplotlib.org/stable/plot_types/index.html): to create figures (plots).\n",
    "- `pathlib`: not as important. To handle folder and file paths.\n",
    "\n",
    "Some syntax examples:\n",
    "- `import pandas` (this imports the pandas module).\n",
    "- `import pandas as pd` (this will allow you to write `pd` in your code instead of `pandas` - just more practical).\n",
    "- `from pandas import read_csv` (this will allow you to import just the `read_csv` function and not the whole of `pandas`.\n",
    "- `import matplotlib.pyplot as plt` (now we are importing a submodule of `matplotlib` (`pyplot`) as `plt`).\n",
    "- `from matplotlib import pyplot as plt` (This is another way of doing it). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c612e36-56c9-4168-9bb3-5e11aa2bdbc7",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de681f-6dc6-4677-b726-3ea20f0c636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f8eb2-38a8-4588-9293-003498e59ae5",
   "metadata": {},
   "source": [
    "## Now let's read a CSV file\n",
    "... and see what it looks like.\n",
    "\n",
    "Specify where the file is with `Path`.  \n",
    "`r'.\\'` means the path is relative to where this file (the code) is.  \n",
    "Read the file with `with open(...) as ... :`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72fb962-92e3-431a-9aa2-822b828d4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(r'.\\Lab work\\6606347\\precipitation\\UKE00105909.csv')\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        print(line.rstrip())\n",
    "        if i >= 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb7793-d2b0-4e5a-9845-d8cd4f62595a",
   "metadata": {},
   "source": [
    "## Now let's read it with pandas\n",
    "\n",
    "It is really this easy!\n",
    "\n",
    "Check out the documentation here:\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c7d8c-1d1e-4ab2-9297-fd28f4a2bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8faa1-2887-4bbc-9f42-b98b03a5ba04",
   "metadata": {},
   "source": [
    "## We can provide more information to the reader too\n",
    "I wish to use the date as the row index.  \n",
    "To parse the dates correctly as `datetime64[ns]` we use the `pd.to_datetime` function.   \n",
    "    You can find all about the format here: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior   \n",
    "We also want to discard all columns beyond PRCP (precipitation)\n",
    "\n",
    "### Precipitation data from this source (GHCN-Daily) is stored in 0.1 mm/day. We must convert to mm/day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d1449-2268-48d0-a913-0eab358db221",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv(file_path, index_col=1, usecols=[0, 1, 2, 3, 4, 5, 6])\n",
    "my_data.index = pd.to_datetime(my_data.index, format='%Y-%m-%d', errors='coerce')\n",
    "my_data.PRCP /= 10\n",
    "\n",
    "station = my_data.iloc[0, 0]\n",
    "print(f'This station is {station}')\n",
    "\n",
    "my_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050e1b2-d862-46c6-ab50-64f5f45ed18c",
   "metadata": {},
   "source": [
    "## Let's see what the data looks like\n",
    "Using matplotlib (included in pandas).  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d26da-921c-4494-95a0-6783a427651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.iloc[:, [-1]].plot()\n",
    "\n",
    "my_data.loc['2015-01-01':'2015-01-31', ['PRCP']].plot(kind='bar')\n",
    "\n",
    "ax = my_data.loc['2015-01-01':'2016-01-01', ['PRCP']].plot(linestyle=' ', marker='.', color='red')\n",
    "_ = ax.set_xlabel('Date')\n",
    "_ = ax.set_ylabel('Precipitation [mm/day]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f6a02-4467-41c1-bcdb-6f8213a47b4b",
   "metadata": {},
   "source": [
    "## Let's now aggregate to yearly\n",
    "We can use the `pd.resample` function:   \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html\n",
    "\n",
    "`my_data.loc[:, ['PRCP']].resample('YS-APR').sum(min_count=365)`  \n",
    "This will focus on the \"PRCP\" column (`,loc()`)  \n",
    "and resample based on a sum of all values on a yearly basis, with start in april `YS-APR` (just an example).  \n",
    "Also, we do a sum that only returns values if there are at least 365 entries `.sum(min_count=365)`.  \n",
    "Finally, all missing data are dropped (`.dropna()`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0babc4e9-c8d1-4302-890e-0fd039adac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_data = my_data.loc[:, ['PRCP']].resample('YS-APR').sum(min_count=365).dropna()\n",
    "yearly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c2470a-3968-4081-9f3f-23f3fc8573d0",
   "metadata": {},
   "source": [
    "## Let's compute statistics\n",
    "We can use .agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea0a6b-65f9-4265-9626-753c63aa004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = yearly_data.agg(['mean', 'std', 'count', 'min', 'max', 'skew'])\n",
    "stats.loc['cv'] = stats.loc['std'] / stats.loc['mean']\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50ac8c0-7b1a-48a7-aa5f-3ab6b33faa4a",
   "metadata": {},
   "source": [
    "## Now let's join, change the header, and export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e780fe1c-49ac-4516-94f5-0ff0268292ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint = pd.concat([yearly_data, stats], axis=0)\n",
    "joint.columns = pd.MultiIndex.from_product([['Precipitation [mm/day]'], [station]], names=['Variable', 'Station'])\n",
    "\n",
    "joint.to_excel(f'parsed_{station}.xlsx')\n",
    "\n",
    "joint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2ce0a-1e4e-4680-b2d2-7e4faee9401b",
   "metadata": {},
   "source": [
    "## Now the magic begins to happen...\n",
    "Lets do this for all stations at once!\n",
    "\n",
    "First, use `glob` to get all files with the `.csv` extension in the `precipitation` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfd282-1e08-4ed0-86ff-804a778ba976",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = Path(r'.\\Lab work\\6606347\\precipitation')\n",
    "\n",
    "for file in folder_path.glob('*.csv'):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0b3d9-6d38-4f11-9678-c7f1970c79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for file in folder_path.glob('*.csv'):\n",
    "    station = file.name.replace('.csv','')\n",
    "    _data = pd.read_csv(file, index_col=0, usecols=[1, 6])\n",
    "    _data.index = pd.to_datetime(_data.index, format='%Y-%m-%d', errors='coerce')\n",
    "    _data.PRCP /= 10\n",
    "\n",
    "    _data.loc[:, ['PRCP']].resample('YS-APR').sum(min_count=365).dropna()\n",
    "    _data.columns = pd.MultiIndex.from_product([['Precipitation [mm/day]'], [station]], names=['Variable', 'Station'])\n",
    "    \n",
    "    all_data.append(_data)\n",
    "\n",
    "full_dataset = pd.concat(all_data, axis=1).dropna()\n",
    "full_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d7fd26-4b52-420d-8210-f000f98bc410",
   "metadata": {},
   "source": [
    "## Can you add the statistics and save to an Excel file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a8a78c-68f9-45d3-8ee4-6665961e85e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climatechange",
   "language": "python",
   "name": "climatechange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
